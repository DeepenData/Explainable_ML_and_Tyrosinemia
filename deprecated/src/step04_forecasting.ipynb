{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "#from ch7.weather.model.model import TcnClassifier\n",
    "#from ch7.weather.utils import sliding_window\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "raw_df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQwC6jRtVUk-2dkk2W3BDJZTOdsS427LN8Ixo-rQF4Afs6ice0rof7qh_EbnAy5lYEGqX-TCSvjpPyr/pub?gid=1713335339&single=true&output=csv',\n",
    "                        index_col=['codigo','Tiempo']).drop(['Fecha','Exposicion'], axis=1)\n",
    "\n",
    "features_cont      = raw_df.columns.tolist()\n",
    "imputed_train_df   = abs(pd.read_csv('imputed_train_df.csv', index_col=['codigo']).drop('Unnamed: 0', axis=1))#.sort_index(inplace=False))\n",
    "imputed_val_df     = abs(pd.read_csv('imputed_val_df.csv', index_col=['codigo']).drop('Unnamed: 0', axis=1))#.sort_index(inplace=False))\n",
    "imputed_df         = pd.concat([imputed_val_df, imputed_train_df])#.sort_index(inplace=False)\n",
    "codigos            = imputed_df.index.get_level_values('codigo').unique().tolist()\n",
    "imputed_df.columns = raw_df.columns.tolist()\n",
    "imputed_df['alfafeto_bad'] = np.where((imputed_df['Alfa-fetoprot'] > 10), 'Yes', 'No')\n",
    "\n",
    "features_cont      = imputed_df.select_dtypes(float).columns.tolist()\n",
    "features_cat = ['alfafeto_bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 52, 3])\n",
      "torch.Size([87, 2])\n"
     ]
    }
   ],
   "source": [
    "df = copy.deepcopy(imputed_df)\n",
    "\n",
    "from ch7.weather.utils import sliding_window\n",
    "w = 3\n",
    "X, Y = [], []\n",
    "for l in codigos:\n",
    "    df_l = df.loc[l]\n",
    "    D = []\n",
    "    for f in features_cont:\n",
    "        D.append(df_l[f].interpolate('linear').fillna(0).values)\n",
    "    for f in features_cat:\n",
    "        D.append(df_l[f].map({'Yes': 1, 'No': 0}).fillna(0).values)\n",
    "        # transpose to time series\n",
    "    TS = []\n",
    "    for i in range(df_l.shape[0]):\n",
    "        row = []\n",
    "        for c in D:\n",
    "            row.append(c[i])\n",
    "        TS.append(row)\n",
    "    in_seq, out_seq = sliding_window(TS, w, 1)\n",
    "    rain_seq = [r[0][-1] for r in out_seq]\n",
    "    X.extend(in_seq)\n",
    "    Y.extend(rain_seq)\n",
    "\n",
    "# Train-Validation Split\n",
    "X_train, Y_train = [], []\n",
    "X_val, Y_val = [], []\n",
    "for i in range(len(X)):\n",
    "    if random.random() > .8:\n",
    "        X_val.append(X[i])\n",
    "        Y_val.append(Y[i])\n",
    "    else:\n",
    "        X_train.append(X[i])\n",
    "        Y_train.append(Y[i])\n",
    "\n",
    "x_train = torch.tensor(X_train).float().transpose(1, 2)\n",
    "\n",
    "params = {\"tcl_num\":          4,\n",
    "        \"tcl_channel_size\": 25,\n",
    "        \"kernel_size\":      4,\n",
    "        \"dropout\":          0.1,\n",
    "        \"slices\":           1,\n",
    "        \"use_bias\":         True,\n",
    "        \"lr\":                0.03388437885302203}\n",
    "tcl_num = params['tcl_num']\n",
    "tcl_channel_size = params['tcl_channel_size']\n",
    "# temporal casual layer channels\n",
    "channel_sizes = [tcl_channel_size] * tcl_num\n",
    "# convolution kernel size\n",
    "kernel_size = params['kernel_size']\n",
    "dropout = params['dropout']\n",
    "slices = params['slices']\n",
    "use_bias = params['use_bias']\n",
    "lr = params['lr']\n",
    "model_params = {\n",
    "    'num_inputs':   len(features_cont) + len(features_cat),\n",
    "    'num_classes':  2,\n",
    "    'num_channels': channel_sizes,\n",
    "    'kernel_size':  kernel_size,\n",
    "    'dropout':      dropout,\n",
    "    'slices':       slices,\n",
    "    'act':          'relu',\n",
    "    'use_bias':     use_bias\n",
    "}\n",
    "from ch7.weather.model.model import TcnClassifier\n",
    "\n",
    "model = TcnClassifier(**model_params)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "prediction = model(x_train)\n",
    "\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 52)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sliding_window(ts, features,Y_idx, target_len = 1):\n",
    "    X, Y = [], []\n",
    "    for i in range(features + target_len, ts.shape[0] + 1):  #\n",
    "        \n",
    "        \n",
    "        X.append(ts[i - (features + target_len):i - target_len,:]) #\n",
    "        Y.append(ts[i - target_len:i, Y_idx]) #\n",
    "        \n",
    "    return  X,  Y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_seq, Y_seq = sliding_window(np.array(df.loc['T15']), w, np.where(df.columns == 'alfafeto_bad')[0][0])\n",
    "\n",
    "np.array(X_seq).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_one_patient_windows(a_patient, target_var, window_length, target_length = 1):\n",
    "    patient_followup      = df.loc[a_patient]\n",
    "    patient_target_var    = patient_followup.pop(target_var)\n",
    "    sequence_length       = patient_followup.shape[0]\n",
    "    window_plus_target    = window_length + target_length\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for i, time_point in enumerate(range(window_plus_target, sequence_length + 1)):\n",
    "        X_multivar_window = patient_followup.iloc[(time_point - window_plus_target) : (time_point - target_length), :]\n",
    "        Y_target          = patient_target_var.iloc[(time_point - target_length) : time_point].map({'Yes': 1, 'No': 0})\n",
    "        X.append(torch.tensor(X_multivar_window.to_numpy()))\n",
    "        y.append(torch.tensor(Y_target.to_list()))\n",
    "                \n",
    "    patient_windows = torch.cat(X).reshape(i+1,window_length,51)\n",
    "    patient_target  = torch.cat(y)\n",
    "    return patient_windows, patient_target\n",
    "\n",
    "patient_windows, patient_target = get_one_patient_windows('T15', 'alfafeto_bad', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "class patients_batch(Dataset):\n",
    "    def __init__(self, codigos, target_var, window_length):\n",
    "        super(patients_batch, self).__init__()\n",
    "        self.codigos       = codigos\n",
    "        self.target_var    = target_var\n",
    "        self.window_length = window_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.codigos)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        one_patient_X, one_patient_y = get_one_patient_windows(self.codigos[index], self.target_var, self.window_length)      \n",
    "        return one_patient_X, one_patient_y\n",
    "    \n",
    "    \n",
    "batch_dataset = patients_batch(codigos, 'alfafeto_bad', 3)\n",
    "batch_loader  = DataLoader(batch_dataset, batch_size=3)\n",
    "\n",
    "\n",
    "\n",
    "X_batch, y_batch = next(iter(batch_loader))\n",
    "\n",
    "X_batch_reshaped = X_batch.reshape(X_batch.shape[0]*X_batch.shape[1],3,51).transpose(1,2).float()#.shape #.shape, y_batch.flatten().shape\n",
    "y_batch_reshaped = y_batch.flatten().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"tcl_num\":          4,\n",
    "        \"tcl_channel_size\": 25,\n",
    "        \"kernel_size\":      4,\n",
    "        \"dropout\":          0.1,\n",
    "        \"slices\":           1,\n",
    "        \"use_bias\":         True,\n",
    "        \"lr\":                0.03388437885302203}\n",
    "tcl_num = params['tcl_num']\n",
    "tcl_channel_size = params['tcl_channel_size']\n",
    "# temporal casual layer channels\n",
    "channel_sizes = [tcl_channel_size] * tcl_num\n",
    "# convolution kernel size\n",
    "kernel_size = params['kernel_size']\n",
    "dropout = params['dropout']\n",
    "slices = params['slices']\n",
    "use_bias = params['use_bias']\n",
    "lr = params['lr']\n",
    "model_params = {\n",
    "    'num_inputs':   len(features_cont),# + len(features_cat),\n",
    "    'num_classes':  2,\n",
    "    'num_channels': channel_sizes,\n",
    "    'kernel_size':  kernel_size,\n",
    "    'dropout':      dropout,\n",
    "    'slices':       slices,\n",
    "    'act':          'relu',\n",
    "    'use_bias':     use_bias\n",
    "}\n",
    "\n",
    "model_params['num_inputs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TcnClassifier(**model_params)\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "cl_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "training_loss = []\n",
    "epochs        = 10\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    for X_batch, y_batch in batch_loader:\n",
    "\n",
    "        X_batch_reshaped = X_batch.reshape(X_batch.shape[0]*X_batch.shape[1],3,51).transpose(1,2).float()#.shape #.shape, y_batch.flatten().shape\n",
    "        y_batch_reshaped = y_batch.flatten().long()\n",
    "        \n",
    "        \n",
    "        prediction = model(X_batch_reshaped)\n",
    "        loss       = cl_loss(prediction, y_batch_reshaped)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.item()) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "317c545ac1557983df223dc9dc6da11914262073b7c77422002e9cb73db54a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
