{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/torch_aa/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "#from ch7.weather.model.model import TcnClassifier\n",
    "#from ch7.weather.utils import sliding_window\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "def load_data():    \n",
    "    \n",
    "    raw_df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQwC6jRtVUk-2dkk2W3BDJZTOdsS427LN8Ixo-rQF4Afs6ice0rof7qh_EbnAy5lYEGqX-TCSvjpPyr/pub?gid=1713335339&single=true&output=csv',\n",
    "                        index_col=['codigo','Tiempo']).drop(['Fecha','Exposicion'], axis=1)\n",
    "    raw_df.sort_index(inplace=True)\n",
    "    #raw_df['adherence'] = np.where((raw_df['SA'] < 0.5) & (raw_df['Tirosina'] < 600) & (raw_df['NTBC_DBS'] > 15), 'Yes', 'No')\n",
    "    \n",
    "    raw_df['alfafeto_bad'] = np.where((raw_df['Alfa-fetoprot'] > 10), 'Yes', 'No')\n",
    "    \n",
    "    #raw_df['adherence']\n",
    "    df_sin_index = raw_df.reset_index()\n",
    "    assert 'Alfa-fetoprot' in df_sin_index.columns.to_list()\n",
    "    return df_sin_index\n",
    "\n",
    "original_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 51\n",
      "No     113\n",
      "Yes     49\n",
      "Name: alfafeto_bad, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQwC6jRtVUk-2dkk2W3BDJZTOdsS427LN8Ixo-rQF4Afs6ice0rof7qh_EbnAy5lYEGqX-TCSvjpPyr/pub?gid=1713335339&single=true&output=csv',\n",
    "                     index_col=['codigo','Tiempo']).drop(['Fecha','Exposicion'], axis=1)\n",
    "\n",
    "raw_df.sort_index(inplace=True)\n",
    "timepoints_per_patient = pd.Series(raw_df.index.get_level_values(0).values).value_counts()\n",
    "smallest_timeseries        = timepoints_per_patient.min()\n",
    "df                     = raw_df.loc[(slice(None), slice(1, smallest_timeseries)), :]\n",
    "print(smallest_timeseries, len(df.columns))\n",
    "\n",
    "\n",
    "\n",
    "imputed_train_df =  abs(pd.read_csv('imputed_train_df.csv', index_col=['codigo']).drop('Unnamed: 0', axis=1))#.sort_index(inplace=False))\n",
    "imputed_val_df   =   abs(pd.read_csv('imputed_val_df.csv', index_col=['codigo']).drop('Unnamed: 0', axis=1))#.sort_index(inplace=False))\n",
    "imputed_df       = pd.concat([imputed_val_df, imputed_train_df])#.sort_index(inplace=False)\n",
    "IDs              =  imputed_df.index.get_level_values(0).unique()\n",
    "\n",
    "timepoints_per_patient = pd.Series(raw_df.index.get_level_values(0).values).value_counts()\n",
    "timeseries_length      =  timepoints_per_patient.min()\n",
    "import itertools\n",
    "\n",
    "#muliindex = itertools.product(IDs, range(1, timeseries_length+1))\n",
    "imputed_df.index = pd.MultiIndex.from_product([IDs, range(1, timeseries_length+1)], names=[\"code\", \"time\"])\n",
    "imputed_df#.sort_index(inplace=True)\n",
    "df = imputed_df\n",
    "df.columns = raw_df.columns\n",
    "df['alfafeto_bad'] = np.where((df['Alfa-fetoprot'] > 10), 'Yes', 'No')\n",
    "\n",
    "print(df['alfafeto_bad'].value_counts())\n",
    "df_sin_index = raw_df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "#df_sin_index.drop( 'Alfa-fetoprot', axis=1, inplace=True)\n",
    "\n",
    "#features_continuos = \n",
    "assert 'Alfa-fetoprot' in df_sin_index.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_train_model(params, epochs, save_model = False, model_name = 'model'):\n",
    "    dir_path = os.path.dirname(os.path.realpath('__file__')) #__file__ solo funciona para la terminal. Para notebook usar ''\n",
    "    \n",
    "    # Explicitly define the end date\n",
    "    #end_date = '2016-01-01'\n",
    "    # Historical data\n",
    "    #df = get_df_until_2016_01_01()\n",
    "    #df = df[df.index < end_date]\n",
    "    df = load_data()\n",
    "    # 3 timepoints as sliding window\n",
    "    w = 3\n",
    "    # Number of epochs for training\n",
    "    #epochs = 50 \n",
    "\n",
    "    # Hyper-parameters:\n",
    "    tcl_num = params['tcl_num']\n",
    "    tcl_channel_size = params['tcl_channel_size']\n",
    "    # temporal casual layer channels\n",
    "    channel_sizes = [tcl_channel_size] * tcl_num\n",
    "    # convolution kernel size\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout = params['dropout']\n",
    "    slices = params['slices']\n",
    "    use_bias = params['use_bias']\n",
    "    lr = params['lr']\n",
    "\n",
    "    # Australia Location for training\n",
    "    #patients_list = list(raw_df.index.get_level_values(0).unique())\n",
    "    codigos =['T01','T02','T03','T04','T05','T06','T07','T08', 'T09', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19']\n",
    "    #locations = ['Albury', 'Newcastle', 'Richmond', 'Sydney', 'Canberra']\n",
    "    # features\n",
    "    features_cont = ['Dosis NTBC (mg/kg)', 'NTBC_DBS', 'SA',\n",
    "    'Metionina', 'Tirosina', 'Fenilalanina', 'RelaciÃ³n Tirosina/Fenilalanina', 'INR', 'PT (seg)', 'Bili Total', 'Bili Directa', 'GPT', 'GOT', 'GGT',\n",
    "    'FosfatasaAlcalina','Alfa-fetoprot', 'Glicemia', 'Alanina', 'Aspartato', 'Glutamato', 'Leucina', 'Ornitina', 'Prolina', 'Tirosina_GSS', 'Carnitina libre', 'Propionilcarnitina', 'Isovalerilcarnitina', 'Tiglilcarnitina',\n",
    "    'Me-Glutarilcarnitina', 'Decanoilcarnitina', 'Tetradecanoilcarnitna', '3-OH-Isovalerilcarnitina', '3-OH-Palmiltoilcarnitna', 'Linoleoilcarnitina', 'Arginina', 'Citrulina', 'Glicina', 'Metionina_GSS', 'Fenilalanina_GSS', 'SA_GSS', 'Valina', 'Acetilcarnitina', 'Butirilcarnitina', 'Glutarilcarnitina', 'Hexanoilcarnitina',\n",
    "    'Octanoilcarnitina', 'Dodecanoilcarnitina', 'Tetradecenoilcarnitna', 'Palmitoilcarnitina', 'Estearoilcarnitina', '3-OH-Linoleoilcarnitina']\n",
    " \n",
    "    features_cat = ['alfafeto_bad']\n",
    "    #features_cont = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am',\n",
    "    #                 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
    "    #                 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
    "    #features_cat = ['RainToday']\n",
    "\n",
    "    X, Y = [], []\n",
    "    for l in codigos:\n",
    "        df_l = df[df['codigo'] == l]\n",
    "        D = []\n",
    "        for f in features_cont:\n",
    "            D.append(df_l[f].interpolate('linear').fillna(0).values)\n",
    "        for f in features_cat:\n",
    "            D.append(df_l[f].map({'Yes': 1, 'No': 0}).fillna(0).values)\n",
    "            # transpose to time series\n",
    "        TS = []\n",
    "        for i in range(df_l.shape[0]):\n",
    "            row = []\n",
    "            for c in D:\n",
    "                row.append(c[i])\n",
    "            TS.append(row)\n",
    "        in_seq, out_seq = sliding_window(TS, w, 1)\n",
    "        rain_seq = [r[0][-1] for r in out_seq]\n",
    "        X.extend(in_seq)\n",
    "        Y.extend(rain_seq)\n",
    "\n",
    "    # Train-Validation Split\n",
    "    X_train, Y_train = [], []\n",
    "    X_val, Y_val = [], []\n",
    "    for i in range(len(X)):\n",
    "        if random.random() > .8:\n",
    "            X_val.append(X[i])\n",
    "            Y_val.append(Y[i])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "\n",
    "    x_train = torch.tensor(X_train).float().transpose(1, 2)\n",
    "    y_train = torch.tensor(Y_train).long()\n",
    "    x_val = torch.tensor(X_val).float().transpose(1, 2)\n",
    "    y_val = torch.tensor(Y_val).long()\n",
    "\n",
    "    model_params = {\n",
    "        'num_inputs':   len(features_cont) + len(features_cat),\n",
    "        'num_classes':  2,\n",
    "        'num_channels': channel_sizes,\n",
    "        'kernel_size':  kernel_size,\n",
    "        'dropout':      dropout,\n",
    "        'slices':       slices,\n",
    "        'act':          'relu',\n",
    "        'use_bias':     use_bias\n",
    "    }\n",
    "    model = TcnClassifier(**model_params)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "    cl_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_params = None\n",
    "    min_val_loss = 1000_000\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "\n",
    "    for t in range(epochs):\n",
    "\n",
    "        prediction = model(x_train)\n",
    "        loss = cl_loss(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_prediction = model(x_val)\n",
    "        val_loss = cl_loss(val_prediction, y_val)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        validation_loss.append(val_loss.item())\n",
    "\n",
    "        if val_loss.item() < min_val_loss:\n",
    "            best_params = copy.deepcopy(model.state_dict())\n",
    "            min_val_loss = val_loss.item()\n",
    "            if save_model:\n",
    "                torch.save(best_params, f'{dir_path}/data/{model_name}.pt')\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(f'best model updated and saved, new min_val_loss: {min_val_loss}')\n",
    "\n",
    "        if t % 1000 == 0:\n",
    "            print(f'Epoch {t}| test: {round(loss.item(),4)}, '\n",
    "                  f'val: {round(val_loss.item(),4)}')\n",
    "            \n",
    "    all_data = torch.cat((x_train, x_val))\n",
    "    all_Ys   = torch.cat((y_train, y_val))\n",
    "\n",
    "\n",
    "    return min_val_loss, model_params, all_data, all_Ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model updated and saved, new min_val_loss: 601.6866455078125\n",
      "Epoch 0| test: 25.4702, val: 601.6866\n",
      "best model updated and saved, new min_val_loss: 81.62939453125\n",
      "best model updated and saved, new min_val_loss: 17.665773391723633\n",
      "best model updated and saved, new min_val_loss: 4.439203262329102\n",
      "best model updated and saved, new min_val_loss: 1.326790452003479\n",
      "best model updated and saved, new min_val_loss: 0.5384372472763062\n",
      "best model updated and saved, new min_val_loss: 0.526439905166626\n",
      "best model updated and saved, new min_val_loss: 0.512729287147522\n",
      "best model updated and saved, new min_val_loss: 0.501803994178772\n",
      "best model updated and saved, new min_val_loss: 0.4862365424633026\n",
      "best model updated and saved, new min_val_loss: 0.47583815455436707\n",
      "best model updated and saved, new min_val_loss: 0.46959441900253296\n",
      "best model updated and saved, new min_val_loss: 0.4538610577583313\n",
      "best model updated and saved, new min_val_loss: 0.45262381434440613\n",
      "best model updated and saved, new min_val_loss: 0.446747750043869\n",
      "best model updated and saved, new min_val_loss: 0.4346877932548523\n",
      "best model updated and saved, new min_val_loss: 0.43225082755088806\n",
      "best model updated and saved, new min_val_loss: 0.39902764558792114\n",
      "Epoch 1000| test: 0.5035, val: 0.4457\n",
      "Epoch 2000| test: 0.5035, val: 0.4455\n",
      "Epoch 3000| test: 0.5035, val: 0.4455\n",
      "Epoch 4000| test: 0.5035, val: 0.4455\n",
      "Epoch 5000| test: 0.5035, val: 0.4455\n",
      "Epoch 6000| test: 0.5035, val: 0.4455\n",
      "Epoch 7000| test: 0.5035, val: 0.4455\n",
      "Epoch 8000| test: 0.5035, val: 0.4455\n",
      "Epoch 9000| test: 0.5035, val: 0.4455\n"
     ]
    }
   ],
   "source": [
    "from ch7.weather.model.model import TcnClassifier\n",
    "from ch7.weather.utils import sliding_window\n",
    "\n",
    "\n",
    "\n",
    "params = {\"tcl_num\":          4,\n",
    "        \"tcl_channel_size\": 25,\n",
    "        \"kernel_size\":      4,\n",
    "        \"dropout\":          0.1,\n",
    "        \"slices\":           1,\n",
    "        \"use_bias\":         True,\n",
    "        \"lr\":                0.03388437885302203}\n",
    "\n",
    "min_val_loss, model_params, all_data, all_Ys = prepare_and_train_model(params, epochs = 10000, save_model = True, model_name = 'tcn_tirosinemia_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model                 = TcnClassifier(**model_params)\n",
    "saved_parameters_path = f\"{os.getcwd()}/data/tcn_tirosinemia_v2.pt\"\n",
    "best_model.load_state_dict(torch.load(saved_parameters_path));\n",
    "torch.save(best_model, \"data/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "learning_data = {'all_data': all_data, 'all_Ys': all_Ys}\n",
    "\n",
    "\n",
    "\n",
    "with open('data/learning_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(learning_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "317c545ac1557983df223dc9dc6da11914262073b7c77422002e9cb73db54a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
